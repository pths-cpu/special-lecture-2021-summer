{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지\n",
    "이 문서에서는 GAN을 이용하여 MNIST의 데이터와 비슷한 이미지를 생성하는 모델을 다룬다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32')\n",
    "x_train = (x_train - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN\n",
    "GAN은 generator와 discriminator가 서로 경쟁하며 학습하여 생성모델을 학습하는 네트워크이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "임의의 크기가 100인 벡터로부터 (28, 28, 1) 크기의 이미지를 생성하는 모델이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    input = keras.layers.Input((100,))\n",
    "    x = keras.layers.Dense(7 * 7 * 256, use_bias=False)(input)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = keras.layers.Reshape((7, 7, 256))(x)\n",
    "    x = keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "  \n",
    "    output = keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "    return keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "(28, 28, 1) 크기의 이미지를 입력받아 해당이미지가 실제 이미지인지 generator가 생성한 이미지인지 구분하는 모델이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    input = keras.layers.Input((28, 28, 1))\n",
    "    x = keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(input)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    return keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.compile(optimizer=keras.optimizers.Adam(0.0001), loss='binary_crossentropy')\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "Generator와 discriminator를 이어붙여 GAN을 구성한다. 이때, `discriminator`를 학습 불가능하게 설정하는 것은 `gan`을 이용해서는 `generator`만 학습하기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_input = keras.layers.Input((100,))\n",
    "generated = generator(gan_input)\n",
    "validity = discriminator(generated)\n",
    "\n",
    "gan = keras.Model(gan_input, validity)\n",
    "discriminator.trainable = False\n",
    "gan.compile(optimizer=keras.optimizers.Adam(0.0001), loss='binary_crossentropy')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 전 generator를 이용하여 생성한 이미지이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.random.normal([1, 100])\n",
    "img = generator(z, training=False)\n",
    "plt.imshow(img[0, :, :, 0] * 127.5 + 127.5, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습은 앞서 로드한 MNIST 데이터셋을 이용한다. MNIST 데이터를 임의로 섞고 `BATCH_SIZE`개씩 쪼갠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices(x_train).shuffle(len(x_train)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 진행됨에 있어서 동일한 입력을 가지고 매 epoch마다 생성모델의 학습정도를 확인할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z = tf.random.normal([10, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습은 discriminator와 generator 각각 진행한다. Discriminator는 실제 이미지와 generator가 생성해낸 이미지를 잘 구분하도록 학습되고, generator는 discriminator를 속이도록 학습된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    for images in train_set:\n",
    "        # generate label\n",
    "        batch_size = len(images)\n",
    "        label_real = tf.ones((batch_size, 1))\n",
    "        label_fake = tf.zeros_like(label_real)\n",
    "\n",
    "        # train discriminator\n",
    "        z = tf.random.normal((batch_size, 100))\n",
    "        generated_image = generator.predict(z)\n",
    "        d_loss_real = discriminator.train_on_batch(images, label_real)\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_image, label_fake)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_losses.append(d_loss)\n",
    "\n",
    "        # train generator\n",
    "        z = tf.random.normal((batch_size, 100))\n",
    "        g_loss = gan.train_on_batch(z, label_real)\n",
    "        g_losses.append(g_loss)\n",
    "    # show progress\n",
    "    display.clear_output(wait=True)\n",
    "    print ('Time for epoch {} is {} sec - d_loss: {} g_loss: {}'.format(epoch + 1, time.time()-start, np.mean(d_losses), np.mean(g_losses)))\n",
    "    generated_images = generator.predict(test_z)\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    for i, img in enumerate(generated_images):\n",
    "        plt.subplot(1, 10, i + 1)\n",
    "        plt.imshow(img[:, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional-GAN\n",
    "Generator가 임의의 이미지를 생성하는 것이 아니라, 특정 조건의 이미지를 생성하도록 할 수도 있다.\n",
    "아래는 특정 숫자를 생성하는 모델을 학습하는 것이다.\n",
    "네트워크의 입력부분을 제외하고, 나머지 부분은 앞서 다룬 GAN과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "입력으로 하나의 랜덤벡터와 생성하고자 하는 라벨을 받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_labeled_generator():\n",
    "    latent = keras.layers.Input((100,))\n",
    "    label = keras.layers.Input((1,), dtype='int32')\n",
    "    label_embeded = keras.layers.Embedding(10, 100)(label)\n",
    "    input = keras.layers.multiply([latent, label_embeded])\n",
    "    \n",
    "    x = keras.layers.Dense(7 * 7 * 256, use_bias=False)(input)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = keras.layers.Reshape((7, 7, 256))(x)\n",
    "    x = keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "  \n",
    "    output = keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "    return keras.Model([latent, label], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_generator = build_labeled_generator()\n",
    "labeled_generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "이미지 하나와 해당 이미지의 라벨을 받는다.\n",
    "Generator와 마찬가지로 입력부분을 제외하고는 기존과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_labeled_discriminator():\n",
    "    image = keras.layers.Input((28, 28, 1))\n",
    "    label = keras.layers.Input((1,), dtype='int32')\n",
    "    label_embeded = keras.layers.Embedding(10, 28 * 28)(label)\n",
    "    label_embeded = keras.layers.Reshape((28, 28, 1))(label_embeded)\n",
    "    input = keras.layers.multiply([image, label_embeded])\n",
    "\n",
    "    x = keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(input)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = keras.layers.LeakyReLU()(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    return keras.Model([image, label], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_discriminator = build_labeled_discriminator()\n",
    "labeled_discriminator.compile(optimizer=keras.optimizers.Adam(0.0001), loss='binary_crossentropy')\n",
    "labeled_discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "Generator와 discriminator를 이용하여 GAN을 구성한다.\n",
    "이때도, 입력에 주의하여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_input = keras.layers.Input((100,))\n",
    "label_input = keras.layers.Input((1,), dtype='int32')\n",
    "generated = generator([gan_input, label_input])\n",
    "validity = discriminator([generated, label_input])\n",
    "\n",
    "labeled_gan = keras.Model([gan_input, label_input], validity)\n",
    "labeled_discriminator.trainable = False\n",
    "labeled_gan.compile(optimizer=keras.optimizers.Adam(0.0001), loss='binary_crossentropy')\n",
    "labeled_gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습\n",
    "앞서와 다르게, 이미지와 해당이미지의 라벨(`y_train`)을 같이 제공해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 진행됨에 있어서 동일한 입력을 가지고 매 epoch마다 생성모델의 학습정도를 확인할 것이다.\n",
    "이때도 마찬가지로, 라벨을 지정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z = tf.random.normal([10, 100])\n",
    "test_label = tf.expand_dims(tf.range(10), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습은 앞서와 같이 진행된다. 다만 각 네트워크의 입력에 라벨이 추가된다는 것만 주의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    for images, labels in train_dataset:\n",
    "        # generate label\n",
    "        batch_size = len(images)\n",
    "        label_real = tf.ones((batch_size, 1))\n",
    "        label_fake = tf.zeros_like(label_real)\n",
    "\n",
    "        # train discriminator\n",
    "        z = tf.random.normal((batch_size, 100))\n",
    "        generated_image = generator.predict([z, labels])\n",
    "        d_loss_real = discriminator.train_on_batch([images, labels], label_real)\n",
    "        d_loss_fake = discriminator.train_on_batch([generated_image, labels], label_fake)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_losses.append(d_loss)\n",
    "\n",
    "        # train generator\n",
    "        z = tf.random.normal((batch_size, 100))\n",
    "        g_loss = gan.train_on_batch([z, labels], label_real)\n",
    "        g_losses.append(g_loss)\n",
    "    # show progress\n",
    "    display.clear_output(wait=True)\n",
    "    print ('Time for epoch {} is {} sec - d_loss: {} g_loss: {}'.format(epoch + 1, time.time()-start, np.mean(d_losses), np.mean(g_losses)))\n",
    "    generated_images = generator.predict([test_z, test_label])\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    for i, img in enumerate(generated_images):\n",
    "        plt.subplot(1, 10, i + 1)\n",
    "        plt.imshow(img[:, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
