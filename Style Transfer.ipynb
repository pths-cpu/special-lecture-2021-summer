{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "from tensorflow.keras.applications import vgg19\n",
    "from tqdm.auto import trange\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Image\n",
    "귀여운 강아지 사진입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_path = keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')\n",
    "display(Image(content_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Image\n",
    "바실리 칸딘스키의 작품입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_path = keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')\n",
    "display(Image(style_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-19\n",
    "VGG-19는 real-world 이미지를 1000가지로 분류하는 ImageNet 데이터셋에 대해 학습된 모델입니다. 이번에는 온라인으로 제공되는 사전 학습된 파라미터를 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg19.VGG19(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 전처리 / 역처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = keras.preprocessing.image.load_img(content_path).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return tf.convert_to_tensor(img)\n",
    "\n",
    "def deprocess_image(x):\n",
    "    x = x.reshape((img_height, img_width, 3))\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 변환\n",
    "이미지의 화풍과 내용을 담는 피쳐를 뽑아 이미지를 변환하는 작업을 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지의 화풍 특징\n",
    "이미지의 화풍 특징은 각 특성 맵의 평균과 특성 맵들 사이의 상관관계로 설명할 수 있는데, 자세한 설명은 생략하도록 하겠습니다.\n",
    "아래의 코드는 이미지의 화풍 특징을 계산할 수 있도록 하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input_tensor):\n",
    "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "    input_shape = tf.shape(input_tensor)\n",
    "    num_locations = tf.cast(input_shape[1] * input_shape[2], tf.float32)\n",
    "    return result / (num_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 특징\n",
    "뉴럴네트워크의 각 층은 이미지의 특징을 나타낸다고 알려져있습니다. 이 중 원하는 층의 출력만을 얻어내는 모델을 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_layer_names = [\n",
    "    'block1_conv1',\n",
    "    'block2_conv1',\n",
    "    'block3_conv1',\n",
    "    'block4_conv1',\n",
    "    'block5_conv1',\n",
    "]\n",
    "content_layer_names = ['block5_conv2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleContentModel(keras.Model):\n",
    "    def __init__(self, model, style_layer_names, content_layer_names):\n",
    "        super(StyleContentModel, self).__init__()\n",
    "        self.style_layer_names = style_layer_names\n",
    "        self.content_layer_names = content_layer_names\n",
    "        \n",
    "        style_layer_outputs = [model.get_layer(name).output for name in style_layer_names]\n",
    "        content_layer_outputs = [model.get_layer(name).output for name in content_layer_names]\n",
    "        self.model = keras.Model([model.input], style_layer_outputs + content_layer_outputs)\n",
    "        self.num_style_layers = len(style_layer_outputs)\n",
    "        self.model.trainable = False\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        outputs = self.model(inputs)\n",
    "        \n",
    "        style_outputs = outputs[:self.num_style_layers]        \n",
    "        style_outputs = [gram_matrix(style_output) for style_output in style_outputs]\n",
    "        style_dict = dict(zip(self.style_layer_names, style_outputs))\n",
    "        \n",
    "        content_outputs = outputs[self.num_style_layers:]\n",
    "        content_dict = dict(zip(self.content_layer_names, content_outputs))\n",
    "        \n",
    "        return {'style': style_dict, 'content': content_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = StyleContentModel(model, style_layer_names, content_layer_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "이미지의 style loss와 content loss를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_weight = 1e-2\n",
    "content_weight = 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_loss(style_outputs, style_targets):\n",
    "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name] - style_targets[name])**2)\n",
    "                          for name in style_outputs.keys()])\n",
    "    style_loss /= len(style_outputs)\n",
    "    return style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(content_outputs, content_targets):\n",
    "    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name] - content_targets[name])**2)\n",
    "                            for name in content_outputs.keys()])\n",
    "    content_loss /= len(content_outputs)\n",
    "    return content_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_content_loss(outputs, targets, style_weight=1, content_weight=1):\n",
    "    style_outputs = outputs['style']\n",
    "    style_targets = targets['style']\n",
    "    sl = style_loss(style_outputs, style_targets)\n",
    "    \n",
    "    content_outputs = outputs['content']\n",
    "    content_targets = targets['content']\n",
    "    cl = style_loss(content_outputs, content_targets)\n",
    "    \n",
    "    loss = style_weight * sl + content_weight * cl\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient\n",
    "정의한 loss를 바탕으로 gradient를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss_and_grads(extractor, image, targets, style_weight=1, content_weight=1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = extractor(image)\n",
    "        loss = style_content_loss(outputs, targets, style_weight, content_weight)\n",
    "    grads = tape.gradient(loss, image)\n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer\n",
    "정의한 loss를 바탕으로 계산한 gradient를 이용하여 이미지를 변환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image = preprocess_image(style_path)\n",
    "style_targets = extractor(style_image)['style']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = preprocess_image(content_path)\n",
    "content_targets = extractor(content_image)['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "경사하강법을 이용하여 loss를 최소화 하도록 최적화하는 모듈입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.optimizers.Adam(learning_rate=5, beta_1=0.99, epsilon=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.Variable(preprocess_image(content_path))\n",
    "targets = {'style': style_targets, 'content': content_targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "iterations = 1000\n",
    "pbar = trange(iterations, postfix={'loss': '-'})\n",
    "for i in pbar:\n",
    "    loss, grads = compute_loss_and_grads(extractor, image, targets, style_weight, content_weight)\n",
    "    opt.apply_gradients([(grads, image)])\n",
    "    pbar.set_postfix({'loss': f'{loss:.2f}'})\n",
    "    if (i + 1) % 100 == 0:\n",
    "        img = deprocess_image(image.numpy())\n",
    "        fname = f'styled_content_image_at_iteration_{i + 1}.png'\n",
    "        keras.preprocessing.image.save_img(fname, img)\n",
    "end = time.time()\n",
    "print(f'소요시간(초): {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 생성된 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(f'styled_content_image_at_iteration_{iterations}.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
